{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#phepy","title":"phepy","text":"<p><code>phepy</code> is a Python package to visually evaluate out-of-distribution detectors using simple toy examples.</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#pip","title":"pip","text":"<p>The <code>phepy</code> package is available on the Python Package Index (PyPI) and can be installed using <pre><code>pip install phepy\n</code></pre> This command can also be run inside a conda environment to install <code>phepy</code> with conda.</p>"},{"location":"#from-source","title":"From Source","text":"<p>First, clone the git repository using <pre><code>git clone https://github.com/juntyr/phepy.git\n</code></pre> or <pre><code>git clone git@github.com:juntyr/phepy.git\n</code></pre></p> <p>Next, enter the repository folder and use <code>pip</code> to install the program: <pre><code>cd phepy &amp;&amp; pip install .\n</code></pre></p>"},{"location":"#usage-example","title":"Usage Example","text":"<p>The following code snippet only provides a minimal example to get started, please refer to the <code>examples</code> folder to find more extensive examples.</p> <pre><code># Import numpy, matplotlib, and sklearn\nimport numpy as np\nimport sklearn\nfrom matplotlib import pyplot as plt\nfrom sklearn.neighbors import LocalOutlierFactor\n# Import phepy, three toy examples, the out-of-distribution (OOD)\n#  detector and scorer, and the plotting helper function\nimport phepy\nfrom phepy.detector import OutOfDistributionDetector, PercentileScorer\nfrom phepy.plot import plot_all_toy_examples\nfrom phepy.toys import ToyExample\nfrom phepy.toys.line import LineToyExample\nfrom phepy.toys.circle import CircleToyExample\nfrom phepy.toys.haystack import HaystackToyExample\n# Generate three toy test cases\nline = LineToyExample(np.random.default_rng(42))\ncircle = CircleToyExample(np.random.default_rng(42))\nhaystack = HaystackToyExample(np.random.default_rng(42))\n# Use the Local Outlier Factor (LOF) [^1] as an OOD detector\nclass LocalOutlierFactorDetector(OutOfDistributionDetector):\n@staticmethod\ndef low_score_is_low_confidence() -&gt; bool:\nreturn True\ndef fit(\nself, X_train: np.ndarray, Y_train: np.ndarray\n):\nself.__X_lof = LocalOutlierFactor(novelty=True).fit(X_train)\nreturn self\ndef predict(self, X_test: np.ndarray) -&gt; np.ndarray:\nreturn self.__X_lof.score_samples(X_test)\n# Generate the plot for the LOF detector and the three test cases\nfig = plot_all_toy_examples(\nscorers = {\n\"Local Outlier Factor\": PercentileScorer(LocalOutlierFactorDetector()),\n},\ntoys = [line, circle, haystack],\ncmap = \"coolwarm\", # use e.g. \"viridis\" to be colour-blind safe\n)\nplt.show()\n</code></pre> <p></p> <p>In the above figure, the single row showcases the Local Outlier Factor (LOF, 1) method, while the three columns contain the following three test cases:</p> <ul> <li>Two groups of training points are scattered along a line in the 2D feature space. The target variable only depends on the location along the line. In this example, points off the line are OOD.</li> <li>The training points are scattered around the sine-displaced boundary of a circle, but none are inside it. The target variable only depends on the location along the boundary. Again, points off the line are OOD.</li> <li>The training points are sampled from a 10-dimensional multivariate normal distribution, where one of the features is set to a constant. This example tests whether an OOD detection method can find a needle in a high-dimensional haystack, i.e. identify that points which do not share the constant are OOD.</li> </ul> <p>The first two panels depict a subset of the training points using black <code>x</code> markers. Note that the first two plots do not have axis labels since the two axes map directly to the 2D feature space axes. The third plot differs and shows the distribution of confidence values on the y-axis for different x-axis values for the constant-in-training feature. The constant value is highlighted as a white line.</p> <p>The Local Outlier Factor (LOF, 1) estimates the training data density around unseen data. Thus, it performs quite well on the line and circle examples where the data points are closely scattered. The LOF classifies the gap between the two groups of training inputs on the line as out-of-distribution (OOD), which may be too conservative if we assume that a machine-learning model can interpolate between the two groups. While LOF produces slightly lower confidence for the OOD inputs in the haystack, it does not clearly identify test data that do not have the constant feature seen in training as out-of-distribution.</p>"},{"location":"#license","title":"License","text":"<p>Licensed under either of</p> <ul> <li>Apache License, Version 2.0 (<code>LICENSE-APACHE</code> or http://www.apache.org/licenses/LICENSE-2.0)</li> <li>MIT license (<code>LICENSE-MIT</code> or http://opensource.org/licenses/MIT)</li> </ul> <p>at your option.</p>"},{"location":"#contribution","title":"Contribution","text":"<p>Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.</p>"},{"location":"#citation","title":"Citation","text":"<p>Please refer to the CITATION.cff file and refer to https://citation-file-format.github.io to extract the citation in a format of your choice.</p> <ol> <li> <p>M. M. Breunig et al. LOF: Identifying Density-Based Local Outliers. Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data. SIGMOD '00. Dallas, Texas, USA: Associ- ation for Computing Machinery, 2000, 93\u2013104. Available from: doi:10.1145/342009.335388.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"api/","title":"phepy","text":""},{"location":"api/#phepy.OutOfDistributionDetector","title":"OutOfDistributionDetector","text":"<p>         Bases: <code>abc.ABC</code></p>"},{"location":"api/#phepy.detector.OutOfDistributionDetector.fit","title":"fit  <code>abstractmethod</code>","text":"<pre><code>fit(\nX_train: np.ndarray, Y_train: np.ndarray\n) -&gt; OutOfDistributionDetector\n</code></pre> Source code in <code>phepy/detector.py</code> <pre><code>@abc.abstractmethod\ndef fit(\nself, X_train: np.ndarray, Y_train: np.ndarray\n) -&gt; OutOfDistributionDetector:\npass\n</code></pre>"},{"location":"api/#phepy.detector.OutOfDistributionDetector.low_score_is_low_confidence","title":"low_score_is_low_confidence  <code>staticmethod</code> <code>abstractmethod</code>","text":"<pre><code>low_score_is_low_confidence() -&gt; bool\n</code></pre> Source code in <code>phepy/detector.py</code> <pre><code>@staticmethod\n@abc.abstractmethod\ndef low_score_is_low_confidence() -&gt; bool:\npass\n</code></pre>"},{"location":"api/#phepy.detector.OutOfDistributionDetector.predict","title":"predict  <code>abstractmethod</code>","text":"<pre><code>predict(X_test: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/detector.py</code> <pre><code>@abc.abstractmethod\ndef predict(self, X_test: np.ndarray) -&gt; np.ndarray:\npass\n</code></pre>"},{"location":"api/#phepy.OutOfDistributionScorer","title":"OutOfDistributionScorer","text":"<pre><code>OutOfDistributionScorer(\ndetector: OutOfDistributionDetector,\n) -&gt; OutOfDistributionScorer\n</code></pre> <p>         Bases: <code>abc.ABC</code></p> Source code in <code>phepy/detector.py</code> <pre><code>@abc.abstractmethod\ndef __init__(\nself, detector: OutOfDistributionDetector\n) -&gt; OutOfDistributionScorer:\nself.__detector = detector\n</code></pre>"},{"location":"api/#phepy.detector.OutOfDistributionScorer.calibrate","title":"calibrate  <code>abstractmethod</code>","text":"<pre><code>calibrate(\nX_valid: np.ndarray, Y_valid: np.ndarray\n) -&gt; OutOfDistributionScorer\n</code></pre> Source code in <code>phepy/detector.py</code> <pre><code>@abc.abstractmethod\ndef calibrate(\nself, X_valid: np.ndarray, Y_valid: np.ndarray\n) -&gt; OutOfDistributionScorer:\npass\n</code></pre>"},{"location":"api/#phepy.detector.OutOfDistributionScorer.detector","title":"detector  <code>property</code>","text":"<pre><code>detector: OutOfDistributionDetector\n</code></pre>"},{"location":"api/#phepy.detector.OutOfDistributionScorer.predict","title":"predict  <code>abstractmethod</code>","text":"<pre><code>predict(X_test: np.ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict the confidence scores for several test data inputs.</p> PARAMETER DESCRIPTION <code>X_test</code> <p>numpy array of shape <code>N_SAMPLES x N_FEATURES</code></p> <p> TYPE: <code>np.ndarray</code> </p> RETURNS DESCRIPTION <code>np.ndarray</code> <p>The array confidence scores of shape <code>N_SAMPLES</code></p> Source code in <code>phepy/detector.py</code> <pre><code>@abc.abstractmethod\ndef predict(self, X_test: np.ndarray) -&gt; np.ndarray:\n\"\"\"Predict the confidence scores for several test data inputs.\n    Args:\n      X_test:\n        numpy array of shape `N_SAMPLES x N_FEATURES`\n    Returns:\n      The array confidence scores of shape `N_SAMPLES`\n    \"\"\"\npass\n</code></pre>"},{"location":"api/#phepy.ToyExample","title":"ToyExample","text":"<p>         Bases: <code>abc.ABC</code></p>"},{"location":"api/#phepy.toys.ToyExample.X_test","title":"X_test  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>X_test: np.ndarray\n</code></pre>"},{"location":"api/#phepy.toys.ToyExample.X_train","title":"X_train  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>X_train: np.ndarray\n</code></pre>"},{"location":"api/#phepy.toys.ToyExample.X_valid","title":"X_valid  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>X_valid: np.ndarray\n</code></pre>"},{"location":"api/#phepy.toys.ToyExample.Y_train","title":"Y_train  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>Y_train: np.ndarray\n</code></pre>"},{"location":"api/#phepy.toys.ToyExample.Y_valid","title":"Y_valid  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>Y_valid: np.ndarray\n</code></pre>"},{"location":"api/#phepy.toys.ToyExample.aspect_ratio","title":"aspect_ratio  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>aspect_ratio: float\n</code></pre>"},{"location":"api/#phepy.toys.ToyExample.is_in_distribution","title":"is_in_distribution  <code>abstractmethod</code>","text":"<pre><code>is_in_distribution(X: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/toys/__init__.py</code> <pre><code>@abc.abstractmethod\ndef is_in_distribution(X: np.ndarray) -&gt; np.ndarray:\npass\n</code></pre>"},{"location":"api/#phepy.toys.ToyExample.plot","title":"plot  <code>abstractmethod</code>","text":"<pre><code>plot(\nconf: np.ndarray,\nax: mpl.axes.Axes,\ncmap: Union[str, mpl.colors.Colormap],\nwith_scatter: bool = True,\n)\n</code></pre> Source code in <code>phepy/toys/__init__.py</code> <pre><code>@abc.abstractmethod\ndef plot(\nself,\nconf: np.ndarray,\nax: mpl.axes.Axes,\ncmap: Union[str, mpl.colors.Colormap],\nwith_scatter: bool = True,\n):\npass\n</code></pre>"},{"location":"api/#phepy.toys.ToyExample.reconstruct","title":"reconstruct  <code>abstractmethod</code>","text":"<pre><code>reconstruct(X: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/toys/__init__.py</code> <pre><code>@abc.abstractmethod\ndef reconstruct(X: np.ndarray) -&gt; np.ndarray:\npass\n</code></pre>"},{"location":"api/SUMMARY/","title":"SUMMARY","text":"<ul> <li>phepy</li> <li>phepy.detector</li> <li>phepy.plot</li> <li>phepy.toys<ul> <li>circle</li> <li>haystack</li> <li>line</li> </ul> </li> </ul>"},{"location":"api/detector/","title":"phepy.detector","text":""},{"location":"api/detector/#phepy.detector.IdentityScorer","title":"IdentityScorer","text":"<pre><code>IdentityScorer(\ndetector: OutOfDistributionDetector,\n) -&gt; IdentityScorer\n</code></pre> <p>         Bases: <code>OutOfDistributionScorer</code></p> Source code in <code>phepy/detector.py</code> <pre><code>def __init__(self, detector: OutOfDistributionDetector) -&gt; IdentityScorer:\nsuper().__init__(detector)\n</code></pre>"},{"location":"api/detector/#phepy.detector.IdentityScorer.calibrate","title":"calibrate","text":"<pre><code>calibrate(\nX_valid: np.ndarray, Y_valid: np.ndarray\n) -&gt; IdentityScorer\n</code></pre> Source code in <code>phepy/detector.py</code> <pre><code>def calibrate(\nself, X_valid: np.ndarray, Y_valid: np.ndarray\n) -&gt; IdentityScorer:\nreturn self\n</code></pre>"},{"location":"api/detector/#phepy.detector.IdentityScorer.predict","title":"predict","text":"<pre><code>predict(X_test: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/detector.py</code> <pre><code>def predict(self, X_test: np.ndarray) -&gt; np.ndarray:\nS_test = self.detector.predict(X_test)\nreturn (\nS_test\nif type(self.detector).low_score_is_low_confidence()\nelse 1.0 - S_test\n)\n</code></pre>"},{"location":"api/detector/#phepy.detector.OutOfDistributionDetector","title":"OutOfDistributionDetector","text":"<p>         Bases: <code>abc.ABC</code></p>"},{"location":"api/detector/#phepy.detector.OutOfDistributionDetector.fit","title":"fit  <code>abstractmethod</code>","text":"<pre><code>fit(\nX_train: np.ndarray, Y_train: np.ndarray\n) -&gt; OutOfDistributionDetector\n</code></pre> Source code in <code>phepy/detector.py</code> <pre><code>@abc.abstractmethod\ndef fit(\nself, X_train: np.ndarray, Y_train: np.ndarray\n) -&gt; OutOfDistributionDetector:\npass\n</code></pre>"},{"location":"api/detector/#phepy.detector.OutOfDistributionDetector.low_score_is_low_confidence","title":"low_score_is_low_confidence  <code>staticmethod</code> <code>abstractmethod</code>","text":"<pre><code>low_score_is_low_confidence() -&gt; bool\n</code></pre> Source code in <code>phepy/detector.py</code> <pre><code>@staticmethod\n@abc.abstractmethod\ndef low_score_is_low_confidence() -&gt; bool:\npass\n</code></pre>"},{"location":"api/detector/#phepy.detector.OutOfDistributionDetector.predict","title":"predict  <code>abstractmethod</code>","text":"<pre><code>predict(X_test: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/detector.py</code> <pre><code>@abc.abstractmethod\ndef predict(self, X_test: np.ndarray) -&gt; np.ndarray:\npass\n</code></pre>"},{"location":"api/detector/#phepy.detector.OutOfDistributionScorer","title":"OutOfDistributionScorer","text":"<pre><code>OutOfDistributionScorer(\ndetector: OutOfDistributionDetector,\n) -&gt; OutOfDistributionScorer\n</code></pre> <p>         Bases: <code>abc.ABC</code></p> Source code in <code>phepy/detector.py</code> <pre><code>@abc.abstractmethod\ndef __init__(\nself, detector: OutOfDistributionDetector\n) -&gt; OutOfDistributionScorer:\nself.__detector = detector\n</code></pre>"},{"location":"api/detector/#phepy.detector.OutOfDistributionScorer.calibrate","title":"calibrate  <code>abstractmethod</code>","text":"<pre><code>calibrate(\nX_valid: np.ndarray, Y_valid: np.ndarray\n) -&gt; OutOfDistributionScorer\n</code></pre> Source code in <code>phepy/detector.py</code> <pre><code>@abc.abstractmethod\ndef calibrate(\nself, X_valid: np.ndarray, Y_valid: np.ndarray\n) -&gt; OutOfDistributionScorer:\npass\n</code></pre>"},{"location":"api/detector/#phepy.detector.OutOfDistributionScorer.detector","title":"detector  <code>property</code>","text":"<pre><code>detector: OutOfDistributionDetector\n</code></pre>"},{"location":"api/detector/#phepy.detector.OutOfDistributionScorer.predict","title":"predict  <code>abstractmethod</code>","text":"<pre><code>predict(X_test: np.ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict the confidence scores for several test data inputs.</p> PARAMETER DESCRIPTION <code>X_test</code> <p>numpy array of shape <code>N_SAMPLES x N_FEATURES</code></p> <p> TYPE: <code>np.ndarray</code> </p> RETURNS DESCRIPTION <code>np.ndarray</code> <p>The array confidence scores of shape <code>N_SAMPLES</code></p> Source code in <code>phepy/detector.py</code> <pre><code>@abc.abstractmethod\ndef predict(self, X_test: np.ndarray) -&gt; np.ndarray:\n\"\"\"Predict the confidence scores for several test data inputs.\n    Args:\n      X_test:\n        numpy array of shape `N_SAMPLES x N_FEATURES`\n    Returns:\n      The array confidence scores of shape `N_SAMPLES`\n    \"\"\"\npass\n</code></pre>"},{"location":"api/detector/#phepy.detector.PercentileScorer","title":"PercentileScorer","text":"<pre><code>PercentileScorer(\ndetector: OutOfDistributionDetector,\n) -&gt; PercentileScorer\n</code></pre> <p>         Bases: <code>OutOfDistributionScorer</code></p> Source code in <code>phepy/detector.py</code> <pre><code>def __init__(\nself, detector: OutOfDistributionDetector\n) -&gt; PercentileScorer:\nsuper().__init__(detector)\n</code></pre>"},{"location":"api/detector/#phepy.detector.PercentileScorer.calibrate","title":"calibrate","text":"<pre><code>calibrate(\nX_valid: np.ndarray, Y_valid: np.ndarray\n) -&gt; PercentileScorer\n</code></pre> Source code in <code>phepy/detector.py</code> <pre><code>def calibrate(\nself, X_valid: np.ndarray, Y_valid: np.ndarray\n) -&gt; PercentileScorer:\nself.__S_valid = np.sort(self.detector.predict(X_valid))\nreturn self\n</code></pre>"},{"location":"api/detector/#phepy.detector.PercentileScorer.predict","title":"predict","text":"<pre><code>predict(X_test: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/detector.py</code> <pre><code>def predict(self, X_test: np.ndarray) -&gt; np.ndarray:\nS_test = np.searchsorted(\nself.__S_valid,\nself.detector.predict(X_test),\n) / len(self.__S_valid)\nreturn (\nS_test\nif type(self.detector).low_score_is_low_confidence()\nelse 1.0 - S_test\n)\n</code></pre>"},{"location":"api/plot/","title":"phepy.plot","text":""},{"location":"api/plot/#phepy.plot.ColorBar","title":"ColorBar  <code>dataclass</code>","text":""},{"location":"api/plot/#phepy.plot.ColorBar.high","title":"high  <code>instance-attribute</code>","text":"<pre><code>high: str\n</code></pre>"},{"location":"api/plot/#phepy.plot.ColorBar.low","title":"low  <code>instance-attribute</code>","text":"<pre><code>low: str\n</code></pre>"},{"location":"api/plot/#phepy.plot.ColorBar.title","title":"title  <code>instance-attribute</code>","text":"<pre><code>title: str\n</code></pre>"},{"location":"api/plot/#phepy.plot.ColorMap","title":"ColorMap  <code>module-attribute</code>","text":"<pre><code>ColorMap = Union[str, mpl.colors.Colormap]\n</code></pre>"},{"location":"api/plot/#phepy.plot.Evaluation","title":"Evaluation  <code>dataclass</code>","text":""},{"location":"api/plot/#phepy.plot.Evaluation.calibrate_time","title":"calibrate_time  <code>instance-attribute</code>","text":"<pre><code>calibrate_time: float\n</code></pre>"},{"location":"api/plot/#phepy.plot.Evaluation.confidence","title":"confidence  <code>instance-attribute</code>","text":"<pre><code>confidence: np.ndarray\n</code></pre>"},{"location":"api/plot/#phepy.plot.Evaluation.detector_size","title":"detector_size  <code>instance-attribute</code>","text":"<pre><code>detector_size: int\n</code></pre>"},{"location":"api/plot/#phepy.plot.Evaluation.expected","title":"expected  <code>instance-attribute</code>","text":"<pre><code>expected: np.ndarray\n</code></pre>"},{"location":"api/plot/#phepy.plot.Evaluation.fit_time","title":"fit_time  <code>instance-attribute</code>","text":"<pre><code>fit_time: float\n</code></pre>"},{"location":"api/plot/#phepy.plot.Evaluation.predict_time","title":"predict_time  <code>instance-attribute</code>","text":"<pre><code>predict_time: float\n</code></pre>"},{"location":"api/plot/#phepy.plot.Evaluation.scorer_size","title":"scorer_size  <code>instance-attribute</code>","text":"<pre><code>scorer_size: int\n</code></pre>"},{"location":"api/plot/#phepy.plot.ScorerCallback","title":"ScorerCallback  <code>module-attribute</code>","text":"<pre><code>ScorerCallback = Union[\nNone,\nCallable[\n[\nOutOfDistributionScorer,\nToyExample,\nEvaluation,\nmpl.axes.Axes,\n],\nNone,\n],\n]\n</code></pre>"},{"location":"api/plot/#phepy.plot.plot_all_toy_examples","title":"plot_all_toy_examples","text":"<pre><code>plot_all_toy_examples(\nscorers: Dict[str, OutOfDistributionScorer],\ntoys: List[ToyExample],\ncmap: Union[ColorMap, List[ColorMap]],\nwith_cbar: Union[\nNone, ColorBar, List[ColorBar]\n] = ColorBar(\ntitle=\"confidence level $c$\", low=\"0.1\", high=\"0.9\"\n),\nwith_titles: bool = True,\nwith_scorer: Union[\nScorerCallback, List[ScorerCallback]\n] = None,\nwith_scatter: Union[bool, List[bool]] = True,\n) -&gt; mpl.figure.Figure\n</code></pre> <p>Plot the out-of-distribution (OOD) detection performance of all given scorers across all given toy examples.</p> <p>Note that the provided scorers and their detectors will be refitted and recalibrated for each toy example.</p> PARAMETER DESCRIPTION <code>scorers</code> <p>mapping from OOD scoring method name to an instance of the method</p> <p> TYPE: <code>Dict[str, OutOfDistributionScorer]</code> </p> <code>toys</code> <p>list of toy examples</p> <p> TYPE: <code>List[ToyExample]</code> </p> <code>cmap</code> <p>name or instance of a matplotlib Colormap that is used to encode the confidence score. A list of colormaps can be given instead to use a different one for each scorer</p> <p> TYPE: <code>Union[ColorMap, List[ColorMap]]</code> </p> <code>with_cbar</code> <p>optional colorbar specification, which is added for each row of subplots. A list of colorbars can be given instead to use a different one for each scorer</p> <p> TYPE: <code>Union[None, ColorBar, List[ColorBar]]</code> DEFAULT: <code>ColorBar(title='confidence level $c$', low='0.1', high='0.9')</code> </p> <code>with_titles</code> <p>whether each method's name should be added as a title to each row of subplots</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>with_scorer</code> <p>optional scoring function which can perform additional evaluation and plot its results. A list of functions can be given instead to use a different one for each scorer</p> <p> TYPE: <code>Union[ScorerCallback, List[ScorerCallback]]</code> DEFAULT: <code>None</code> </p> <code>with_scatter</code> <p>whether a subset of the training data should be scattered in each subplot panel. A list of booleans can be given instead to use a different one for each scorer</p> <p> TYPE: <code>Union[bool, List[bool]]</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>mpl.figure.Figure</code> <p>The created matplotlib figure.</p> Source code in <code>phepy/plot.py</code> <pre><code>def plot_all_toy_examples(\nscorers: Dict[str, OutOfDistributionScorer],\ntoys: List[ToyExample],\ncmap: Union[ColorMap, List[ColorMap]],\nwith_cbar: Union[None, ColorBar, List[ColorBar]] = ColorBar(\ntitle=\"confidence level $c$\",\nlow=\"0.1\",\nhigh=\"0.9\",\n),\nwith_titles: bool = True,\nwith_scorer: Union[ScorerCallback, List[ScorerCallback]] = None,\nwith_scatter: Union[bool, List[bool]] = True,\n) -&gt; mpl.figure.Figure:\n\"\"\"Plot the out-of-distribution (OOD) detection performance\n    of all given scorers across all given toy examples.\n    Note that the provided scorers and their detectors will be\n    refitted and recalibrated for each toy example.\n    Args:\n      scorers:\n        mapping from OOD scoring method name to an instance\n        of the method\n      toys:\n        list of toy examples\n      cmap:\n        name or instance of a matplotlib Colormap that\n        is used to encode the confidence score.\n        A list of colormaps can be given instead to use a\n        different one for each scorer\n      with_cbar:\n        optional colorbar specification, which is added for\n        each row of subplots.\n        A list of colorbars can be given instead to use a\n        different one for each scorer\n      with_titles:\n        whether each method's name should be added as a\n        title to each row of subplots\n      with_scorer:\n        optional scoring function which can perform\n        additional evaluation and plot its results.\n        A list of functions can be given instead to use a\n        different one for each scorer\n      with_scatter:\n        whether a subset of the training data should be\n        scattered in each subplot panel.\n        A list of booleans can be given instead to use a\n        different one for each scorer\n    Returns:\n      The created matplotlib figure.\n    \"\"\"\nwidth_ratios = [toy.aspect_ratio for toy in toys]\nif with_cbar:\nwidth_ratios += [0.1]\nfig, axs = mpl.pyplot.subplots(\nlen(scorers),\nlen(toys) + int(with_cbar is not None),\nfigsize=(4 * np.sum(width_ratios), 4 * len(scorers)),\ngridspec_kw={\"width_ratios\": width_ratios},\n)\naxs = np.array(axs).reshape(\n(len(scorers), len(toys) + int(with_cbar is not None))\n)\nif not isinstance(cmap, list):\ncmap = [cmap for _ in scorers]\nif not isinstance(with_cbar, list):\nwith_cbar = [with_cbar for _ in scorers]\nif not isinstance(with_scorer, list):\nwith_scorer = [with_scorer for _ in scorers]\nif not isinstance(with_scatter, list):\nwith_scatter = [with_scatter for _ in scorers]\nfor (\naxr,\n(title, scorer),\ncmap,\nwith_cbar,\nwith_scorer,\nwith_scatter,\n) in zip(axs, scorers.items(), cmap, with_cbar, with_scorer, with_scatter):\nfor ax, toy in zip(axr, toys):\npre_fit = time.perf_counter()\nscorer.detector.fit(toy.X_train, toy.Y_train)\npost_fit = time.perf_counter()\nscorer.calibrate(toy.X_valid, toy.Y_valid)\npost_calibrate = time.perf_counter()\nconf = scorer.predict(toy.X_test)\npost_predict = time.perf_counter()\ndetector_size = _getsize(scorer.detector)\nscorer_size = _getsize(scorer)\ntoy.plot(conf, ax, cmap, with_scatter)\nif with_scorer is not None:\nwith_scorer(\nscorer,\ntoy,\nEvaluation(\nfit_time=post_fit - pre_fit,\ncalibrate_time=post_calibrate - post_fit,\npredict_time=post_predict - post_calibrate,\ndetector_size=detector_size,\nscorer_size=scorer_size - detector_size,\nexpected=toy.is_in_distribution(toy.X_test),\nconfidence=conf,\n),\nax,\n)\nif with_titles and len(axr) &gt; int(with_cbar is not None):\naxr[0].text(\n0.5,\n0.95,\ntitle,\nha=\"center\",\nva=\"top\",\nsize=20,\nc=\"white\",\nbbox=dict(facecolor=\"black\", alpha=0.25, edgecolor=\"white\"),\ntransform=axr[0].transAxes,\n)\nif with_cbar is not None and len(axr) &gt; 1:\naxr[-1].spines[\"top\"].set_visible(False)\naxr[-1].spines[\"right\"].set_visible(False)\naxr[-1].spines[\"bottom\"].set_visible(False)\naxr[-1].spines[\"left\"].set_visible(False)\naxr[-1].xaxis.set_visible(False)\naxr[-1].set_yticks([0.1, 0.9])\naxr[-1].set_yticklabels([with_cbar.low, with_cbar.high])\naxr[-1].set_ylabel(with_cbar.title, labelpad=-13)\naxr[-1].yaxis.set_label_position(\"right\")\naxr[-1].yaxis.tick_right()\naxr[-1].imshow(\n[[x / 100, x / 100] for x in range(100, -1, -1)],\ncmap=cmap,\ninterpolation=\"bicubic\",\nvmin=0.0,\nvmax=1.0,\nextent=[-0.05, 0.05, 0.0, 1.0],\nzorder=-2,\n)\nfig.tight_layout()\nfig.subplots_adjust(wspace=0.1, hspace=0.1)\nreturn fig\n</code></pre>"},{"location":"api/toys/","title":"phepy.toys","text":""},{"location":"api/toys/#phepy.toys.ToyExample","title":"ToyExample","text":"<p>         Bases: <code>abc.ABC</code></p>"},{"location":"api/toys/#phepy.toys.ToyExample.X_test","title":"X_test  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>X_test: np.ndarray\n</code></pre>"},{"location":"api/toys/#phepy.toys.ToyExample.X_train","title":"X_train  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>X_train: np.ndarray\n</code></pre>"},{"location":"api/toys/#phepy.toys.ToyExample.X_valid","title":"X_valid  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>X_valid: np.ndarray\n</code></pre>"},{"location":"api/toys/#phepy.toys.ToyExample.Y_train","title":"Y_train  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>Y_train: np.ndarray\n</code></pre>"},{"location":"api/toys/#phepy.toys.ToyExample.Y_valid","title":"Y_valid  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>Y_valid: np.ndarray\n</code></pre>"},{"location":"api/toys/#phepy.toys.ToyExample.aspect_ratio","title":"aspect_ratio  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>aspect_ratio: float\n</code></pre>"},{"location":"api/toys/#phepy.toys.ToyExample.is_in_distribution","title":"is_in_distribution  <code>abstractmethod</code>","text":"<pre><code>is_in_distribution(X: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/toys/__init__.py</code> <pre><code>@abc.abstractmethod\ndef is_in_distribution(X: np.ndarray) -&gt; np.ndarray:\npass\n</code></pre>"},{"location":"api/toys/#phepy.toys.ToyExample.plot","title":"plot  <code>abstractmethod</code>","text":"<pre><code>plot(\nconf: np.ndarray,\nax: mpl.axes.Axes,\ncmap: Union[str, mpl.colors.Colormap],\nwith_scatter: bool = True,\n)\n</code></pre> Source code in <code>phepy/toys/__init__.py</code> <pre><code>@abc.abstractmethod\ndef plot(\nself,\nconf: np.ndarray,\nax: mpl.axes.Axes,\ncmap: Union[str, mpl.colors.Colormap],\nwith_scatter: bool = True,\n):\npass\n</code></pre>"},{"location":"api/toys/#phepy.toys.ToyExample.reconstruct","title":"reconstruct  <code>abstractmethod</code>","text":"<pre><code>reconstruct(X: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/toys/__init__.py</code> <pre><code>@abc.abstractmethod\ndef reconstruct(X: np.ndarray) -&gt; np.ndarray:\npass\n</code></pre>"},{"location":"api/toys/circle/","title":"phepy.toys.circle","text":""},{"location":"api/toys/circle/#phepy.toys.circle.CircleToyExample","title":"CircleToyExample","text":"<pre><code>CircleToyExample(\nrng: np.random.Generator, N: int = 10000\n) -&gt; CircleToyExample\n</code></pre> <p>         Bases: <code>ToyExample</code></p> Source code in <code>phepy/toys/circle.py</code> <pre><code>def __init__(\nself, rng: np.random.Generator, N: int = 10_000\n) -&gt; CircleToyExample:\nY = np.sin(np.linspace(0, np.pi * 8.0, N))\nX1 = np.sin(np.linspace(0, np.pi * 2.0, N)) * (5 + Y)\nX2 = np.cos(np.linspace(0, np.pi * 2.0, N)) * (5 + Y)\nX1 += rng.normal(loc=0.0, scale=0.1, size=N)\nX2 += rng.normal(loc=0.0, scale=0.1, size=N)\nself.__X_train = np.stack([X1, X2], axis=1)\nself.__Y_train = Y\nX1 = np.sin(np.linspace(0, np.pi * 2.0, N)) * (5 + Y)\nX2 = np.cos(np.linspace(0, np.pi * 2.0, N)) * (5 + Y)\nX1 += rng.normal(loc=0.0, scale=0.1, size=N)\nX2 += rng.normal(loc=0.0, scale=0.1, size=N)\nself.__X_valid = np.stack([X1, X2], axis=1)\nself.__Y_valid = Y\nX1T, X2T = np.mgrid[-7.5:7.5:0.01, -7.5:7.5:0.01]\nX1T = X1T.flatten()\nX2T = X2T.flatten()\nself.__X_test = np.stack([X1T, X2T], axis=1)\n</code></pre>"},{"location":"api/toys/circle/#phepy.toys.circle.CircleToyExample.X_test","title":"X_test  <code>property</code>","text":"<pre><code>X_test: np.ndarray\n</code></pre>"},{"location":"api/toys/circle/#phepy.toys.circle.CircleToyExample.X_train","title":"X_train  <code>property</code>","text":"<pre><code>X_train: np.ndarray\n</code></pre>"},{"location":"api/toys/circle/#phepy.toys.circle.CircleToyExample.X_valid","title":"X_valid  <code>property</code>","text":"<pre><code>X_valid: np.ndarray\n</code></pre>"},{"location":"api/toys/circle/#phepy.toys.circle.CircleToyExample.Y_train","title":"Y_train  <code>property</code>","text":"<pre><code>Y_train: np.ndarray\n</code></pre>"},{"location":"api/toys/circle/#phepy.toys.circle.CircleToyExample.Y_valid","title":"Y_valid  <code>property</code>","text":"<pre><code>Y_valid: np.ndarray\n</code></pre>"},{"location":"api/toys/circle/#phepy.toys.circle.CircleToyExample.aspect_ratio","title":"aspect_ratio  <code>property</code>","text":"<pre><code>aspect_ratio: float\n</code></pre>"},{"location":"api/toys/circle/#phepy.toys.circle.CircleToyExample.is_in_distribution","title":"is_in_distribution","text":"<pre><code>is_in_distribution(X: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/toys/circle.py</code> <pre><code>def is_in_distribution(self, X: np.ndarray) -&gt; np.ndarray:\n# Two standard deviations off the mean -&gt; 95.45% interval\nreturn np.linalg.norm(X - self.reconstruct(X), axis=1) &lt;= 0.2\n</code></pre>"},{"location":"api/toys/circle/#phepy.toys.circle.CircleToyExample.plot","title":"plot","text":"<pre><code>plot(\nconf: np.ndarray,\nax: mpl.axes.Axes,\ncmap: Union[str, mpl.colors.Colormap],\nwith_scatter: bool = True,\n)\n</code></pre> Source code in <code>phepy/toys/circle.py</code> <pre><code>def plot(\nself,\nconf: np.ndarray,\nax: mpl.axes.Axes,\ncmap: Union[str, mpl.colors.Colormap],\nwith_scatter: bool = True,\n):\nN_skip = len(self.X_train) // 40\nax.imshow(\nconf.reshape(np.mgrid[-7.5:7.5:0.01, -7.5:7.5:0.01][0].shape).T,\ncmap=cmap,\nvmin=0.0,\nvmax=1.0,\nextent=[-7.5, 7.5, -7.5, 7.5],\norigin=\"lower\",\ninterpolation=\"bicubic\",\nrasterized=True,\n)\nax.set_xlim(-7.5, 7.5)\nax.set_ylim(-7.5, 7.5)\nif with_scatter:\nax.scatter(\nself.X_train[::N_skip, 0],\nself.X_train[::N_skip, 1],\nc=\"white\",\nmarker=\"x\",\nlw=3,\ns=48,\n)\nax.scatter(\nself.X_train[::N_skip, 0],\nself.X_train[::N_skip, 1],\nc=\"black\",\nmarker=\"x\",\n)\nax.axis(\"off\")\n</code></pre>"},{"location":"api/toys/circle/#phepy.toys.circle.CircleToyExample.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(X: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/toys/circle.py</code> <pre><code>def reconstruct(self, X: np.ndarray) -&gt; np.ndarray:\n# Project X onto the sin-perturbed circle\nangle = _my_arctan2(X[:, 0], X[:, 1])\nY = np.sin(angle * 4.0)\nX1 = np.sin(angle) * (5.0 + Y)\nX2 = np.cos(angle) * (5.0 + Y)\n# return np.stack([X1, X2], axis=1)\nreturn X1.reshape((len(X), 1)) * np.array([[1, 0]]) + X2.reshape(\n(len(X), 1)\n) * np.array([[0, 1]])\n</code></pre>"},{"location":"api/toys/haystack/","title":"phepy.toys.haystack","text":""},{"location":"api/toys/haystack/#phepy.toys.haystack.HaystackToyExample","title":"HaystackToyExample","text":"<pre><code>HaystackToyExample(\nrng: np.random.Generator, N: int = 10000\n) -&gt; HaystackToyExample\n</code></pre> <p>         Bases: <code>ToyExample</code></p> Source code in <code>phepy/toys/haystack.py</code> <pre><code>def __init__(\nself, rng: np.random.Generator, N: int = 10_000\n) -&gt; HaystackToyExample:\nN *= 2\nn = 10\na = 2\n# https://stats.stackexchange.com/a/124554\nA = np.matrix(\n[rng.normal(size=n) + rng.normal(size=1) * a for i in range(n)]\n)\nA = A * np.transpose(A)\nD_half = np.diag(np.diag(A) ** (-0.5))\ncovs = D_half * A * D_half\nX = rng.multivariate_normal(np.zeros(shape=n), covs, size=N)\nX[:, 3] = -0.42\n# Since X[:,3] is const, it does not matter what its multiplier is\nC = rng.choice([-2, -1, 0, 0, 1, 2], size=n)\nY = np.dot(X, C)\nI_train = rng.choice(N, size=N // 2, replace=False)\nI_valid = np.ones(N)\nI_valid[I_train] = 0\n(I_valid,) = np.nonzero(I_valid)\nself.__X_train = X[I_train]\nself.__Y_train = Y[I_train]\nself.__X_valid = X[I_valid]\nself.__Y_valid = Y[I_valid]\nXT = rng.multivariate_normal(np.zeros(shape=n), covs, size=N // 2)\nXT[:, 3] = (rng.random(size=N // 2) - 0.5) - 0.42\n# Provide some definitely ID points\nXT[np.random.choice(N // 2, size=N // 200), 3] = -0.42\nself.__X_test = XT\n</code></pre>"},{"location":"api/toys/haystack/#phepy.toys.haystack.HaystackToyExample.X_test","title":"X_test  <code>property</code>","text":"<pre><code>X_test: np.ndarray\n</code></pre>"},{"location":"api/toys/haystack/#phepy.toys.haystack.HaystackToyExample.X_train","title":"X_train  <code>property</code>","text":"<pre><code>X_train: np.ndarray\n</code></pre>"},{"location":"api/toys/haystack/#phepy.toys.haystack.HaystackToyExample.X_valid","title":"X_valid  <code>property</code>","text":"<pre><code>X_valid: np.ndarray\n</code></pre>"},{"location":"api/toys/haystack/#phepy.toys.haystack.HaystackToyExample.Y_train","title":"Y_train  <code>property</code>","text":"<pre><code>Y_train: np.ndarray\n</code></pre>"},{"location":"api/toys/haystack/#phepy.toys.haystack.HaystackToyExample.Y_valid","title":"Y_valid  <code>property</code>","text":"<pre><code>Y_valid: np.ndarray\n</code></pre>"},{"location":"api/toys/haystack/#phepy.toys.haystack.HaystackToyExample.aspect_ratio","title":"aspect_ratio  <code>property</code>","text":"<pre><code>aspect_ratio: float\n</code></pre>"},{"location":"api/toys/haystack/#phepy.toys.haystack.HaystackToyExample.is_in_distribution","title":"is_in_distribution","text":"<pre><code>is_in_distribution(X: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/toys/haystack.py</code> <pre><code>def is_in_distribution(self, X: np.ndarray) -&gt; np.ndarray:\n# Can only be ID if the constant feature value matches\nreturn X[:, 3] == -0.42\n</code></pre>"},{"location":"api/toys/haystack/#phepy.toys.haystack.HaystackToyExample.plot","title":"plot","text":"<pre><code>plot(\nconf: np.ndarray,\nax: mpl.axes.Axes,\ncmap: Union[str, mpl.colors.Colormap],\nwith_scatter: bool = True,\n)\n</code></pre> Source code in <code>phepy/toys/haystack.py</code> <pre><code>def plot(\nself,\nconf: np.ndarray,\nax: mpl.axes.Axes,\ncmap: Union[str, mpl.colors.Colormap],\nwith_scatter: bool = True,\n):\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nax.spines[\"bottom\"].set_visible(False)\nax.spines[\"left\"].set_visible(False)\nax.set_xticks([-0.42 - 0.4, -0.42, -0.42 + 0.4])\nax.set_xticklabels([r\"$-0.4 \\sigma$\", \"const\", r\"$+0.4 \\sigma$\"])\nax.get_yaxis().set_visible(False)\nax.axvline(-0.42, c=\"white\", lw=7, zorder=-1)\n# with_scatter is ignored\nax.scatter(self.X_test[:, 3], conf, c=\"white\", s=6, rasterized=True)\nax.scatter(self.X_test[:, 3], conf, c=\"black\", s=1, rasterized=True)\nax.imshow(\n[[x / 100, x / 100] for x in range(100, -1, -1)],\ncmap=cmap,\ninterpolation=\"bicubic\",\nvmin=0.0,\nvmax=1.0,\nextent=[-0.93, 0.09, -0.01, 1.01],\nzorder=-2,\n)\n</code></pre>"},{"location":"api/toys/haystack/#phepy.toys.haystack.HaystackToyExample.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(X: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/toys/haystack.py</code> <pre><code>def reconstruct(self, X: np.ndarray) -&gt; np.ndarray:\n# Project X onto the line\nreturn X * np.array(\n[[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]\n) - np.array([[0.0, 0.0, 0.0, 0.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])\n</code></pre>"},{"location":"api/toys/line/","title":"phepy.toys.line","text":""},{"location":"api/toys/line/#phepy.toys.line.LineToyExample","title":"LineToyExample","text":"<pre><code>LineToyExample(\nrng: np.random.Generator, N: int = 10000\n) -&gt; LineToyExample\n</code></pre> <p>         Bases: <code>ToyExample</code></p> Source code in <code>phepy/toys/line.py</code> <pre><code>def __init__(\nself, rng: np.random.Generator, N: int = 10_000\n) -&gt; LineToyExample:\nX1 = np.concatenate(\n[np.linspace(0, 4, N // 2), np.linspace(6, 10, N // 2)]\n)\nX2 = 1 + X1 * 0.5 + rng.normal(loc=0.0, scale=0.1, size=N)\nX1 += rng.normal(loc=0.0, scale=0.1, size=N)\nself.__X_train = np.stack([X1, X2], axis=1)\nself.__Y_train = X1 * np.sqrt(1.25)\nX1 = np.concatenate(\n[np.linspace(0, 4, N // 2), np.linspace(6, 10, N // 2)]\n)\nX2 = 1 + X1 * 0.5 + rng.normal(loc=0.0, scale=0.1, size=N)\nX1 += rng.normal(loc=0.0, scale=0.1, size=N)\nself.__X_valid = np.stack([X1, X2], axis=1)\nself.__Y_valid = X1 * np.sqrt(1.25)\nX1T, X2T = np.mgrid[-2:12:0.01, -1:8:0.01]\nX1T = X1T.flatten()\nX2T = X2T.flatten()\nself.__X_test = np.stack([X1T, X2T], axis=1)\n</code></pre>"},{"location":"api/toys/line/#phepy.toys.line.LineToyExample.X_test","title":"X_test  <code>property</code>","text":"<pre><code>X_test: np.ndarray\n</code></pre>"},{"location":"api/toys/line/#phepy.toys.line.LineToyExample.X_train","title":"X_train  <code>property</code>","text":"<pre><code>X_train: np.ndarray\n</code></pre>"},{"location":"api/toys/line/#phepy.toys.line.LineToyExample.X_valid","title":"X_valid  <code>property</code>","text":"<pre><code>X_valid: np.ndarray\n</code></pre>"},{"location":"api/toys/line/#phepy.toys.line.LineToyExample.Y_train","title":"Y_train  <code>property</code>","text":"<pre><code>Y_train: np.ndarray\n</code></pre>"},{"location":"api/toys/line/#phepy.toys.line.LineToyExample.Y_valid","title":"Y_valid  <code>property</code>","text":"<pre><code>Y_valid: np.ndarray\n</code></pre>"},{"location":"api/toys/line/#phepy.toys.line.LineToyExample.aspect_ratio","title":"aspect_ratio  <code>property</code>","text":"<pre><code>aspect_ratio: float\n</code></pre>"},{"location":"api/toys/line/#phepy.toys.line.LineToyExample.is_in_distribution","title":"is_in_distribution","text":"<pre><code>is_in_distribution(X: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/toys/line.py</code> <pre><code>def is_in_distribution(self, X: np.ndarray) -&gt; np.ndarray:\n# Two standard deviations off the mean -&gt; 95.45% interval\nreturn np.linalg.norm(X - self.reconstruct(X), axis=1) &lt;= 0.2\n</code></pre>"},{"location":"api/toys/line/#phepy.toys.line.LineToyExample.plot","title":"plot","text":"<pre><code>plot(\nconf: np.ndarray,\nax: mpl.axes.Axes,\ncmap: Union[str, mpl.colors.Colormap],\nwith_scatter: bool = True,\n)\n</code></pre> Source code in <code>phepy/toys/line.py</code> <pre><code>def plot(\nself,\nconf: np.ndarray,\nax: mpl.axes.Axes,\ncmap: Union[str, mpl.colors.Colormap],\nwith_scatter: bool = True,\n):\nN_skip = len(self.X_train) // 40\nax.imshow(\nconf.reshape(np.mgrid[-2:12:0.01, -1:8:0.01][0].shape).T,\ncmap=cmap,\nvmin=0.0,\nvmax=1.0,\nextent=[-2, 12, -1, 8],\norigin=\"lower\",\ninterpolation=\"bicubic\",\nrasterized=True,\n)\nax.set_xlim(-2, 12)\nax.set_ylim(-1, 8)\nif with_scatter:\nax.scatter(\nself.X_train[::N_skip, 0],\nself.X_train[::N_skip, 1],\nc=\"white\",\nmarker=\"x\",\nlw=3,\ns=48,\n)\nax.scatter(\nself.X_train[::N_skip, 0],\nself.X_train[::N_skip, 1],\nc=\"black\",\nmarker=\"x\",\n)\nax.axis(\"off\")\n</code></pre>"},{"location":"api/toys/line/#phepy.toys.line.LineToyExample.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(X: np.ndarray) -&gt; np.ndarray\n</code></pre> Source code in <code>phepy/toys/line.py</code> <pre><code>def reconstruct(self, X: np.ndarray) -&gt; np.ndarray:\n# Project X onto the line\nreturn np.array([[0.0, 1.0]]) + np.array([[1.0, 0.5]]) * (\nnp.matmul((X - np.array([0.0, 1.0])), np.array([[1.0], [0.5]]))\n/ np.matmul(np.array([[1.0, 0.5]]), np.array([[1.0], [0.5]]))\n)\n</code></pre>"}]}